# Mini-Prosperia ‚Äì Challenge (OCR + IA)

## Implementaciones realizadas

1) **OCR con Tesseract (obligatorio)**
   Se hace uso de la libreria [Tesseract.js](https://www.npmjs.com/package/tesseract.js) para reconocer caracteres en los documentos enviados.

   - **Uso de PDFs con Tesseract.js**: Tesseract.js no permite procesar PDFs de manera directa, por lo que se convierten todos los documentos de tipo PDF a imagen antes de ser procesados. Para esto se utiliza la libreria [pdf2pic](https://www.npmjs.com/package/pdf2pic) mediante la creacion de un servicio de conversi√≥n.

   - **Preprocesamiento de Imagenes**
   Se implementaron las tecnicas mas comunes de preprocesamiento de imagenes para aumentar la precision del OCR.
   Los pasos a seguir son:
      1. Invertir Imagen.
      2. Convertir a Escala de Grises.
      3. Reducci√≥n de Ruido (Mediana).
      4. Binarizaci√≥n de Imagen con Umbralizaci√≥n adaptativa (Otsu).
      [Fuente](https://www.youtube.com/watch?v=ADV-AjAXHdc)

      - **Preprocesamiento con Sharp**
      Se utiliza la librer√≠a [Sharp](https://www.npmjs.com/package/sharp) para realizar operaciones de preprocesamiento en las im√°genes. Esta implementaci√≥n se llev√≥ a cabo con apoyo de IA.

      - **Preprocesamiento con Canvas**
      Se utiliza la librer√≠a [canvas](https://www.npmjs.com/package/canvas) para realizar operaciones de preprocesamiento en las im√°genes.
      La implementaci√≥n fue obtenida de: [dev.to](https://dev.to/mathewthe2/using-javascript-to-preprocess-images-for-ocr-1jc)
      El preprocesamiento implementado con canvas fue comentado y no se utiliz√≥ en la implementaci√≥n final.

      - **Consideraciones**
      Tambi√©n se puede usar [OpenCV](https://opencv.org/) para el preprocesamiento de im√°genes, este parece ser un m√©todo m√°s com√∫n.

      - **IMPORTANTE**
      No hubo aumento de precision al probar el preprocesamiento con ninguna de las dos implementaciones, por lo tanto es **recomendable** utilizar su mock para saltar esta etapa. `PRE_PROCESS_PROVIDER=mock`

   - **Configuracion del Worker de Tesseract**: Se configura el worker de Tesseract para que utilice los idiomas adecuados (Espa√±ol e Ingl√©s), pero tambi√©n se agrega `osd` para la detecci√≥n de orientaci√≥n y lenguaje del documento. Tesseract.js utiliza data pre-entrenada para mejorar la precisi√≥n del reconocimiento, existen varios repositorios con modelos entrenados disponibles, pero esta libreria utiliza los mejores modelos disponibles.
   Tambi√©n se usa Tesseract con una whitelist de caracteres permitidos para mejorar la precisi√≥n.
   `tessedit_char_whitelist: '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë√º√ú%:.,-$'`

2) **Estructuraci√≥n y/o parsing de campos**
   Una vez obtenido el texto crudo del documento se procede a estructurarlo y extraer los campos relevantes, si bien esto se puede lograr utilizando expresiones regulares, tambi√©n se puede implementar un modelo de IA que ayude a identificar y clasificar la informaci√≥n de manera m√°s precisa.

   - **Configuracion del Modelo de IA**: Utilizando gpt-4o-mini como modelo, se realizaron configuraciones espec√≠ficas para mejorar la extracci√≥n de informaci√≥n. La mas importante fue el uso del output estructurado para guiar al modelo con los campos esperados junto a la descripcion de cada uno. Se bajo un poco la temperatura, reduciendo levemente la "creatividad" del modelo.

3) **Categorizaci√≥n con OpenAI usando el Relay**
   Por ultimo, categorizamos los recibos, como datos de entrada se usan los `accounts` existentes en la base de datos, el nombre del vendedor obtenido en el paso anterior, y el texto crudo del OCR.

   - **Configuracion del Modelo de IA**: Se utiliza el mismo modelo que para la estructuraci√≥n, se aplican configuraciones similares, incluyendo el uso de output estructurado con la lista de IDs de `accounts`. Se aumenta levemente la temperatura.

4) **C√°lculo de campos faltantes**
   Como herramienta de fallback, se implementa un servicio que permite calcular los campos num√©ricos principales cuando no se detectan directamente en el OCR o parsing. Los campos involucrados son:

   - **Monto total** (`amount`)
   - **Subtotal** (`subtotalAmount`)
   - **Impuesto** (`taxAmount`)
   - **Porcentaje de impuesto** (`taxPercentage`)

   Se hacen c√°lculos b√°sicos para completar los valores faltantes y asegurar la persistencia de todos los campos requeridos.

5) **Persistencia de datos**
   Todos los datos obtenidos persisten en la base de datos, especificamente en las tablas `Receipts`, `Transactions`, `Vendor` y `vendorIdentifications`.

   - **Creacion de Vendors**: se implementa un servicio que permite crear nuevos vendors a partir de nuevas identificaciones obtenidas en el Documento. En caso de que estos ya existan, se actualizan.

6) **UI**
   Se implementa una interfaz de usuario simple que permite a los usuarios subir im√°genes o PDFs y ver la transacci√≥n desglosada. La UI se basa en un formulario en `/public/index.html`.

   ![UI Screenshot](https://github.com/user-attachments/assets/9e2cb643-7130-41fd-97c3-a14b49b2e241)

7) **Logging**
   Se implementa un sistema de logging usando la libreria [Pino](https://www.npmjs.com/package/pino)

   - **Logs Rotativos y Persistencia**
   Junto con [pino-roll](https://www.npmjs.com/package/pino-roll) se configura un log rotativo para lograr persistencia. Los logs se guardan en la carpeta `./logs` y se rotan diariamente o cuando alcanzan un tama√±o m√°ximo de 20MB.

   - **Decorador de Metodos**
   Se implementa un decorador de metodos para agregar logs de entrada y salida a los metodos de los servicios.

8) **Docker**
   Se crea un nuevo archivo `docker-compose.production.yml` para definir los servicios y configuraciones necesarias para el entorno de producci√≥n.
   Servicios:

   - **db**: Contenedor de la base de datos PostgreSQL. Se expone el puerto 5432 (para pruebas)
   - **server**: Contenedor de la aplicaci√≥n.  La migraci√≥n y seed de la base de datos se realiza autom√°ticamente al iniciar el contenedor. Se expone el puerto 3000. Se hace bind a la carpeta `./logs` para persistencia de logs.

## Diagrama de Flujo

   [Disponible en Drive](https://drive.google.com/file/d/1bei-hDz6V2hjabtRqzD_5__VyL0GTXuI/view?usp=sharing)

## Correr localmente con Docker

   Una vez clonado el repositorio puedes:

   ```bash
   cp .env.example .env
   npm run compose-prod:up
   ```

## Correr localmente (sin Docker)

   ```bash
   cp .env.example .env
   npm i
   npm run db:generate
   npm run db:migrate
   npm run db:seed
   npm run build
   npm run start
   ```

# Planteamiento

**Objetivo:** a partir de un recibo (PDF o imagen) extraer y persistir **toda** esta informaci√≥n:

- **Total** (`amount`)
- **Subtotal** (`subtotalAmount`)
- **Impuesto** (`taxAmount`)
- **% de impuesto** (`taxPercentage`)
- **Vendor name**
- **Vendor identifications** (RUC/NIT/CIF u otros)
- **Categorizar autom√°ticamente** el gasto a una **cuenta contable** (`Account`)

**Bonus:** una **UI** simple para subir la imagen/PDF y ver la transacci√≥n desglosada (hay un form base en `/public/index.html`).

---

## üîß Lo que debes implementar (claves marcadas con `TODO` en el c√≥digo)

1) **OCR con Tesseract (obligatorio)**
   - Implementa el provider de Tesseract en `src/services/ocr/*` para extraer `rawText` desde una imagen/PDF.
   - Sugerencia: idioma `eng+spa`.

2) **Estructuraci√≥n y/o parsing de campos**
   - Detecta y llena: `amount`, `subtotalAmount`, `taxAmount`, `taxPercentage`, `date`, `invoiceNumber`, `vendorName`, `vendorIdentifications` (RUC/NIT/CIF).
   - Puedes combinar **reglas** + **IA** para mejorar exactitud.

3) **Categorizaci√≥n con OpenAI usando el Relay (obligatorio para la categor√≠a)**
   - Llama al **relay** (endpoint HTTP) para obtener la **categor√≠a contable** recomendada a partir del texto del recibo y/o vendor.
   - Integra el resultado asignando un `accountId` existente (usa las cuentas del seed).

> En el repo hay heur√≠sticas base y stubs de IA. Los puntos exactos a tocar est√°n marcados con `// TODO:` en m√≥dulos de **OCR**, **AI** y **parsing/categorization**.

---

## üöÄ Setup r√°pido

```bash
cp .env.example .env
npm i
npm run compose:up           # o usa Postgres local si no tienes Docker
npm run db:generate
npm run db:migrate
npm run db:seed
npm run dev
```

- API: `http://localhost:3000`
- UI:  `http://localhost:3000/` (form para subir)

### Endpoints
- `POST /api/receipts` (form-data con `file`)
- `GET /api/receipts/:id`
- `POST /api/receipts/:id/reparse`
- `POST /api/transactions` (ejemplo de CRUD base)

---

## üß† Proveedores

- **OCR**: `tesseract` (**obligatorio implementarlo**). Tambi√©n existe `mock` para pruebas.
- **IA**:
  - `mock` (gratis) ‚Äî funciona sin costos.
  - **OpenAI v√≠a Relay** (recomendado para categorizaci√≥n):
    - No necesitas una API key propia.
    - Usa el **relay** provisto y tu **token** para las llamadas.

### Configuraci√≥n para usar el Relay (OpenAI)

En tu `.env` del challenge define:

```
AI_PROVIDER=openai
OPENAI_BASE_URL=https://prosperia-openai-relay-production.up.railway.app
PROSPERIA_TOKEN=nombre-apellido
```

- `PROSPERIA_TOKEN` ser√° tu **token de acceso** al relay y **es tu nombre-apellido** (por ejemplo: `andres-prato`).
- El cliente del challenge enviar√° las requests a:
  - `POST ${OPENAI_BASE_URL}/openai/chat`
  - Header requerido: `X-Prosperia-Token: ${PROSPERIA_TOKEN}`
- **Importante:** La API key real de OpenAI vive en el relay (servidor).
- Utiliza el Relay para poder usar gpt-4o-mini a tu disposici√≥n para el challenge

---

## ‚úÖ Criterios de evaluaci√≥n

1. **Exactitud** de los campos extra√≠dos: `amount`, `subtotalAmount`, `taxAmount`, `taxPercentage`, `vendorName`, `vendorIdentifications`.
2. **Categorizaci√≥n autom√°tica**: correcto mapeo a un `Account` existente (v√≠a relay + OpenAI).
3. **Calidad del c√≥digo** (TypeScript), manejo de errores y DX (logs, validaciones, mensajes).
4. **Persistencia**: Prisma + migraciones + seeds funcionando.
5. **Bonus**: UI funcional, tests, Docker (opcional).

---

## üß™ C√≥mo probaremos (resumen)

- Subiremos varias im√°genes/PDF a `POST /api/receipts`.
- Veremos el JSON persistido y los campos detectados.
- Verificaremos que se asigna una **categor√≠a contable** v√°lida.
- (Si hay UI) Subiremos un archivo desde `/` y validaremos el desglose.

----